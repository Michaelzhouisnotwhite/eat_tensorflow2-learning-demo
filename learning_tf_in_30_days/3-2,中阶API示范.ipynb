{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 3-2,中阶API示范\n",
    "\n",
    "下面的范例使用TensorFlow的中阶API实现线性回归模型和和DNN二分类模型。\n",
    "\n",
    "TensorFlow的中阶API主要包括各种模型层，损失函数，优化器，数据管道，特征列等等。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\r\n",
    "\r\n",
    "#打印时间分割线\r\n",
    "@tf.function\r\n",
    "def printbar():\r\n",
    "    today_ts = tf.timestamp()%(24*60*60)\r\n",
    "\r\n",
    "    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\r\n",
    "    minite = tf.cast((today_ts%3600)//60,tf.int32)\r\n",
    "    second = tf.cast(tf.floor(today_ts%60),tf.int32)\r\n",
    "    \r\n",
    "    def timeformat(m):\r\n",
    "        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\r\n",
    "            return(tf.strings.format(\"0{}\",m))\r\n",
    "        else:\r\n",
    "            return(tf.strings.format(\"{}\",m))\r\n",
    "    \r\n",
    "    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\r\n",
    "                timeformat(second)],separator = \":\")\r\n",
    "    tf.print(\"==========\"*8+timestring)\r\n",
    "\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 一，线性回归模型"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1，准备数据**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np \r\n",
    "import pandas as pd\r\n",
    "from matplotlib import pyplot as plt \r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras import layers,losses,metrics,optimizers\r\n",
    "\r\n",
    "#样本数量\r\n",
    "n = 400\r\n",
    "\r\n",
    "# 生成测试用数据集\r\n",
    "X = tf.random.uniform([n,2],minval=-10,maxval=10) \r\n",
    "w0 = tf.constant([[2.0],[-3.0]])\r\n",
    "b0 = tf.constant([[3.0]])\r\n",
    "Y = X@w0 + b0 + tf.random.normal([n,1],mean = 0.0,stddev= 2.0)  # @表示矩阵乘法,增加正态扰动\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 数据可视化\r\n",
    "# %matplotlib inline\r\n",
    "# %config InlineBackend.figure_format = 'svg'\r\n",
    "plt.figure(figsize = (12,5))\r\n",
    "ax1 = plt.subplot(121)\r\n",
    "ax1.scatter(X[:,0],Y[:,0], c = \"b\")\r\n",
    "plt.xlabel(\"x1\")\r\n",
    "plt.ylabel(\"y\",rotation = 0)\r\n",
    "\r\n",
    "ax2 = plt.subplot(122)\r\n",
    "ax2.scatter(X[:,1],Y[:,0], c = \"g\")\r\n",
    "plt.xlabel(\"x2\")\r\n",
    "plt.ylabel(\"y\",rotation = 0)\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./data/3-2-01-回归数据可视化.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#构建输入数据管道\r\n",
    "ds = tf.data.Dataset.from_tensor_slices((X,Y)) \\\r\n",
    "     .shuffle(buffer_size = 100).batch(10) \\\r\n",
    "     .prefetch(tf.data.experimental.AUTOTUNE)  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2，定义模型**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = layers.Dense(units = 1) \r\n",
    "model.build(input_shape = (2,)) #用build方法创建variables\r\n",
    "model.loss_func = losses.mean_squared_error\r\n",
    "model.optimizer = optimizers.SGD(learning_rate=0.001)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**3，训练模型**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#使用autograph机制转换成静态图加速\r\n",
    "\r\n",
    "@tf.function\r\n",
    "def train_step(model, features, labels):\r\n",
    "    with tf.GradientTape() as tape:\r\n",
    "        predictions = model(features)\r\n",
    "        loss = model.loss_func(tf.reshape(labels,[-1]), tf.reshape(predictions,[-1]))\r\n",
    "    grads = tape.gradient(loss,model.variables)\r\n",
    "    model.optimizer.apply_gradients(zip(grads,model.variables))\r\n",
    "    return loss\r\n",
    "\r\n",
    "# 测试train_step效果\r\n",
    "features,labels = next(ds.as_numpy_iterator())\r\n",
    "train_step(model,features,labels)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_model(model,epochs):\r\n",
    "    for epoch in tf.range(1,epochs+1):\r\n",
    "        loss = tf.constant(0.0)\r\n",
    "        for features, labels in ds:\r\n",
    "            loss = train_step(model,features,labels)\r\n",
    "        if epoch%50==0:\r\n",
    "            printbar()\r\n",
    "            tf.print(\"epoch =\",epoch,\"loss = \",loss)\r\n",
    "            tf.print(\"w =\",model.variables[0])\r\n",
    "            tf.print(\"b =\",model.variables[1])\r\n",
    "train_model(model,epochs = 200)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "================================================================================17:01:48\n",
    "epoch = 50 loss =  2.56481647\n",
    "w = [[1.99355531]\n",
    " [-2.99061537]]\n",
    "b = [3.09484935]\n",
    "================================================================================17:01:51\n",
    "epoch = 100 loss =  5.96198225\n",
    "w = [[1.98028314]\n",
    " [-2.96975136]]\n",
    "b = [3.09501529]\n",
    "================================================================================17:01:54\n",
    "epoch = 150 loss =  4.79625702\n",
    "w = [[2.00056171]\n",
    " [-2.98774862]]\n",
    "b = [3.09567738]\n",
    "================================================================================17:01:58\n",
    "epoch = 200 loss =  8.26704407\n",
    "w = [[2.00282311]\n",
    " [-2.99300027]]\n",
    "b = [3.09406662]\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 结果可视化\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "w,b = model.variables\n",
    "\n",
    "plt.figure(figsize = (12,5))\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.scatter(X[:,0],Y[:,0], c = \"b\",label = \"samples\")\n",
    "ax1.plot(X[:,0],w[0]*X[:,0]+b[0],\"-r\",linewidth = 5.0,label = \"model\")\n",
    "ax1.legend()\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"y\",rotation = 0)\n",
    "\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.scatter(X[:,1],Y[:,0], c = \"g\",label = \"samples\")\n",
    "ax2.plot(X[:,1],w[1]*X[:,1]+b[0],\"-r\",linewidth = 5.0,label = \"model\")\n",
    "ax2.legend()\n",
    "plt.xlabel(\"x2\")\n",
    "plt.ylabel(\"y\",rotation = 0)\n",
    "\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./data/3-2-02-回归结果可视化.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 二， DNN二分类模型"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1，准备数据**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,losses,metrics,optimizers\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "#正负样本数量\n",
    "n_positive,n_negative = 2000,2000\n",
    "\n",
    "#生成正样本, 小圆环分布\n",
    "r_p = 5.0 + tf.random.truncated_normal([n_positive,1],0.0,1.0)\n",
    "theta_p = tf.random.uniform([n_positive,1],0.0,2*np.pi) \n",
    "Xp = tf.concat([r_p*tf.cos(theta_p),r_p*tf.sin(theta_p)],axis = 1)\n",
    "Yp = tf.ones_like(r_p)\n",
    "\n",
    "#生成负样本, 大圆环分布\n",
    "r_n = 8.0 + tf.random.truncated_normal([n_negative,1],0.0,1.0)\n",
    "theta_n = tf.random.uniform([n_negative,1],0.0,2*np.pi) \n",
    "Xn = tf.concat([r_n*tf.cos(theta_n),r_n*tf.sin(theta_n)],axis = 1)\n",
    "Yn = tf.zeros_like(r_n)\n",
    "\n",
    "#汇总样本\n",
    "X = tf.concat([Xp,Xn],axis = 0)\n",
    "Y = tf.concat([Yp,Yn],axis = 0)\n",
    "\n",
    "\n",
    "#可视化\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.scatter(Xp[:,0].numpy(),Xp[:,1].numpy(),c = \"r\")\n",
    "plt.scatter(Xn[:,0].numpy(),Xn[:,1].numpy(),c = \"g\")\n",
    "plt.legend([\"positive\",\"negative\"]);\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./data/3-1-03-分类数据可视化.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#构建输入数据管道\n",
    "ds = tf.data.Dataset.from_tensor_slices((X,Y)) \\\n",
    "     .shuffle(buffer_size = 4000).batch(100) \\\n",
    "     .prefetch(tf.data.experimental.AUTOTUNE) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2, 定义模型**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class DNNModel(tf.Module):\n",
    "    def __init__(self,name = None):\n",
    "        super(DNNModel, self).__init__(name=name)\n",
    "        self.dense1 = layers.Dense(4,activation = \"relu\") \n",
    "        self.dense2 = layers.Dense(8,activation = \"relu\")\n",
    "        self.dense3 = layers.Dense(1,activation = \"sigmoid\")\n",
    "\n",
    "     \n",
    "    # 正向传播\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape = [None,2], dtype = tf.float32)])  \n",
    "    def __call__(self,x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        y = self.dense3(x)\n",
    "        return y\n",
    "    \n",
    "model = DNNModel()\n",
    "model.loss_func = losses.binary_crossentropy\n",
    "model.metric_func = metrics.binary_accuracy\n",
    "model.optimizer = optimizers.Adam(learning_rate=0.001)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 测试模型结构\n",
    "(features,labels) = next(ds.as_numpy_iterator())\n",
    "\n",
    "predictions = model(features)\n",
    "\n",
    "loss = model.loss_func(tf.reshape(labels,[-1]),tf.reshape(predictions,[-1]))\n",
    "metric = model.metric_func(tf.reshape(labels,[-1]),tf.reshape(predictions,[-1]))\n",
    "\n",
    "tf.print(\"init loss:\",loss)\n",
    "tf.print(\"init metric\",metric)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "init loss: 1.13653195\n",
    "init metric 0.5\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**3，训练模型**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#使用autograph机制转换成静态图加速\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(features)\n",
    "        loss = model.loss_func(tf.reshape(labels,[-1]), tf.reshape(predictions,[-1]))\n",
    "    grads = tape.gradient(loss,model.trainable_variables)\n",
    "    model.optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "    \n",
    "    metric = model.metric_func(tf.reshape(labels,[-1]), tf.reshape(predictions,[-1]))\n",
    "    \n",
    "    return loss,metric\n",
    "\n",
    "# 测试train_step效果\n",
    "features,labels = next(ds.as_numpy_iterator())\n",
    "train_step(model,features,labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "(<tf.Tensor: shape=(), dtype=float32, numpy=1.2033114>,\n",
    " <tf.Tensor: shape=(), dtype=float32, numpy=0.47>)\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_model(model,epochs):\n",
    "    for epoch in tf.range(1,epochs+1):\n",
    "        loss, metric = tf.constant(0.0),tf.constant(0.0)\n",
    "        for features, labels in ds:\n",
    "            loss,metric = train_step(model,features,labels)\n",
    "        if epoch%10==0:\n",
    "            printbar()\n",
    "            tf.print(\"epoch =\",epoch,\"loss = \",loss, \"accuracy = \",metric)\n",
    "train_model(model,epochs = 60)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "================================================================================17:07:36\n",
    "epoch = 10 loss =  0.556449413 accuracy =  0.79\n",
    "================================================================================17:07:38\n",
    "epoch = 20 loss =  0.439187407 accuracy =  0.86\n",
    "================================================================================17:07:40\n",
    "epoch = 30 loss =  0.259921253 accuracy =  0.95\n",
    "================================================================================17:07:42\n",
    "epoch = 40 loss =  0.244920313 accuracy =  0.9\n",
    "================================================================================17:07:43\n",
    "epoch = 50 loss =  0.19839409 accuracy =  0.92\n",
    "================================================================================17:07:45\n",
    "epoch = 60 loss =  0.126151696 accuracy =  0.95\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 结果可视化\n",
    "fig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize = (12,5))\n",
    "ax1.scatter(Xp[:,0].numpy(),Xp[:,1].numpy(),c = \"r\")\n",
    "ax1.scatter(Xn[:,0].numpy(),Xn[:,1].numpy(),c = \"g\")\n",
    "ax1.legend([\"positive\",\"negative\"]);\n",
    "ax1.set_title(\"y_true\");\n",
    "\n",
    "Xp_pred = tf.boolean_mask(X,tf.squeeze(model(X)>=0.5),axis = 0)\n",
    "Xn_pred = tf.boolean_mask(X,tf.squeeze(model(X)<0.5),axis = 0)\n",
    "\n",
    "ax2.scatter(Xp_pred[:,0].numpy(),Xp_pred[:,1].numpy(),c = \"r\")\n",
    "ax2.scatter(Xn_pred[:,0].numpy(),Xn_pred[:,1].numpy(),c = \"g\")\n",
    "ax2.legend([\"positive\",\"negative\"]);\n",
    "ax2.set_title(\"y_pred\");\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](./data/3-2-04-分类结果可视化.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n",
    "\n",
    "也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n",
    "\n",
    "![算法美食屋二维码.jpg](./data/算法美食屋二维码.jpg)"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}